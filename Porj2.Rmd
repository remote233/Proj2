---
title: "Project2"
author: "Yiliang Yuan & Yiyu Lin"
date: "2022-11-26"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(gridExtra)
library(GGally)
library(reshape2)
```

***
## 1 Data Collection and Exploration
## (a)
Global climate change is an important scientific and public topic. In this topic, there’s a prediction that, in the Arctic area, surface air temperatures will have the strongest dependency on increasing atmospheric carbon dioxide levels. In further study of this dependency, the key is to detect the cloud condition. This is a challenging problem if we apply two previous MISR operational algorithms because of the similarities between the remote sensing image of clouds and that of ice- or snow-covered surface. Thus, based on the new idea of searching for cloud-free surface, the goal of this study is to develop a computationally efficient algorithm with the combination of classification and clustering methods, but without the requiring human intervention
The data in this study represents 10 MISR orbits from Path 26, which is 360 km wide, and starting at the Arctic until Antarctica. The time between each orbit is 16 days. In this path, there’re 180 blocks to collect data, but for each orbit case, only 6 blocks’ data will be taken. In these 60 blocks, the author removed 3 blocks whose cloud condition can be detected by the previous MISR algorithm. Therefore, there are 57 blocks data units with 7,114,248 1.1-km resolution pixels with 36 radiation measurements for each pixel in this study. Author hand-labeled these data, with “1” for cloudy, “-1” for not cloudy, and “0” for ambiguous.
There’re also three key features used in this study to differentiate surface pixels from cloudy pixels. The first is CORR. It is used to differentiate MISR images of the same scene from different MISR viewing directions. The second is SDAn, the standard deviation of MISR nadir camera pixel values across a scene. The last one, NDAI, is a normalized difference angular index. It can be used to characterize the changes in a scene with changes in the MISR view direction.
In conclusion, both the newly-developed ELCM and ELCM-QDA algorithm return a result with better accuracy and better coverage, when compared to the results generated from previous MISR algorithm. Moreover, the ELCM-QDA algorithm can generate more information and perform consistently on probability prediction. The impact of this work is significant. Statisticians will play a more important role in data analyses and statistical thinking will take more responsibility in solving modern scientific problems.



## (b)
```{r}
image1=read.csv('imagem1.txt',sep='',header=FALSE)
image2=read.csv('imagem2.txt', sep='',header=FALSE)
image3=read.csv('imagem3.txt', sep='',header=FALSE)
colnames(image1) = c('y','x','expert_label','NDAI','SD','CORR','DF','CF','BF','AF','AN')
colnames(image2) = c('y','x','expert_label','NDAI','SD','CORR','DF','CF','BF','AF','AN')
colnames(image3) = c('y','x','expert_label','NDAI','SD','CORR','DF','CF','BF','AF','AN')
image <- rbind(image1,image2,image3)
```

First of all, we can find the percentage of pixels for the different classes in different images as:
```{r}
per1 <- image1 %>%
  group_by(expert_label)%>%
  summarise(image1 = round(n()/nrow(.),3))
per2 <- image2 %>%
  group_by(expert_label)%>%
  summarise(image2 = round(n()/nrow(.),3))
per3 <- image3 %>%
  group_by(expert_label)%>%
  summarise(image3 = round(n()/nrow(.),3))
per_total <- image %>%
  group_by(expert_label)%>%
  summarise(image_total = round(n()/nrow(.),3))
per_combined <- list(per1,per2,per3,per_total)
per_combined %>% reduce(full_join, by='expert_label')
```
Then, we can plot the maps of different images by x,y corrdinates values with expert labels as colors as:
```{r}
myColors = c("gray40","black","white")
p1 = ggplot(image1, aes(x, y, colour = factor(expert_label))) + 
  geom_point(show.legend = FALSE)+
  scale_color_manual(values=myColors)+
  labs(colour="expert_label")
p2 = ggplot(image2, aes(x, y, colour = factor(expert_label))) + 
  geom_point(show.legend = FALSE)+
  scale_color_manual(values=myColors)+
  labs(colour="expert_label")
p3 = ggplot(image3, aes(x, y, colour = factor(expert_label))) + 
  geom_point(show.legend = FALSE)+
  scale_color_manual(values=myColors)+
  labs(colour="expert_label")
```
    
```{r,fig.width=8,fig.height=3}
gg_legend <- ggplot(image1, aes(x, y, colour = factor(expert_label))) + 
  geom_point()+
  scale_color_manual(values=myColors)+
  labs(colour="expert_label") +
  theme(legend.position = "bottom")
extract_legend <- function(my_ggp) {
  step1 <- ggplot_gtable(ggplot_build(my_ggp))
  step2 <- which(sapply(step1$grobs, function(x) x$name) == "guide-box")
  step3 <- step1$grobs[[step2]]
  return(step3)
}
shared_legend <- extract_legend(gg_legend)
grid.arrange(arrangeGrob(p1,p2,p3,ncol=3), shared_legend,nrow = 2, heights = c(10, 1))
```
In the graphs above, we plot each pixels as a single dot in the graph, but they can be merged to a large area with the same color. This means pixels from each class tend to be surrounded by the pixels from the same class. Thus, for all the dataset, we cannot treat samples or pixels as i.i.d. 


## (c)
```{r}
image = image %>%
  mutate(expert_label = factor(expert_label))
image_cor = round(cor(image[,4:11]),2)
get_upper_tri <- function(corr){
    corr[lower.tri(corr)]<- NA
    return(corr)
}
upper_tri = get_upper_tri(image_cor)
melted_image_corr <- melt(upper_tri, na.rm = TRUE)

heatmap <- ggplot(data = melted_image_corr, aes(Var2, Var1, fill = value))+
 geom_tile(color = "white")+
 scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
   midpoint = 0, limit = c(-1,1), space = "Lab", 
   name="Correlations") +
  theme_minimal()+ 
 theme(axis.text.x = element_text(angle = 45, vjust = 1, 
    size = 12, hjust = 1))+
 coord_fixed()

heatmap + 
geom_text(aes(Var2, Var1, label = value), color = "black", size = 4) +
theme(
  axis.title.x = element_blank(),
  axis.title.y = element_blank(),
  panel.grid.major = element_blank(),
  panel.border = element_blank(),
  panel.background = element_blank(),
  axis.ticks = element_blank(),
  legend.justification = c(1, 0),
  legend.position = c(0.6, 0.7),
  legend.direction = "horizontal")+
  guides(fill = guide_colorbar(barwidth = 7, barheight = 1,
                title.position = "top", title.hjust = 0.5))
```
Since the size of our dataset is too large and there are 7 variables to pair, it might not be a good idea to use pairs plot here. Instead, we can draw a heat map for the correlations between the features themselves, and the result is very interesting. NDAI, SD and CORR are positively correlated, and all the radiance variables are also positively correlated. However, radiance and other features(CORR,NDAI,SD) are negatively correlated. In addition, we find that radiance angle AN, AF, BF, CF are strongly correlated since their correlations are all larger than 0.75. Radiance angle DF is strongly correlated to radiance angle CF and BF, but its correlations with radiance angle AF and AN are not that strong.

```{r}
p1 = ggplot(image,aes(x=expert_label, y=NDAI))+
  geom_boxplot()
p2 = ggplot(image,aes(x=expert_label, y=SD))+
  geom_boxplot()
p3 = ggplot(image,aes(x=expert_label, y=CORR))+
  geom_boxplot()
p4 = ggplot(image,aes(x=expert_label, y=DF))+
  geom_boxplot()
p5 = ggplot(image,aes(x=expert_label, y=CF))+
  geom_boxplot()
p6 = ggplot(image,aes(x=expert_label, y=BF))+
  geom_boxplot()
p7 = ggplot(image,aes(x=expert_label, y=AF))+
  geom_boxplot()
p8 = ggplot(image,aes(x=expert_label, y=AN))+
  geom_boxplot()
```

```{r,fig.width=9,fig.height=3}
grid.arrange(p1,p2,p3,ncol=3)
```
By plotting the boxplots of NDAI, SD, and CORR with expert label as x-axis, we find that cloud class tends to have higher values of NDAI, SD and CORR.
```{r,fig.width=9,fig.height=6}
grid.arrange(p4,p5,p6,p7,p8,ncol=3)
```
Again, by plotting boxplots of DF, CF, BF, AF and AN with expert labels as x-axis, we find that cloud class tends to have smaller values of radiance in different angles except that in DF. For radiance angle DF, all the classes have similar distributions of radiance values, so it is hard to tell differences between cloud and no cloud classes.


# 2 Preparation
```{r}

```



# 3 Modeling

# 4 Diagnostics 


# Acknowledgement
GridExtra to combine shared labels: https://statisticsglobe.com/add-common-legend-to-combined-ggplot2-plots-in-r/
Heatmap for correlations: http://www.sthda.com/english/wiki/ggplot2-quick-correlation-matrix-heatmap-r-software-and-data-visualization

***
